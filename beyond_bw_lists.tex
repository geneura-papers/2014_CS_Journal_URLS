\documentclass[preprint]{elsarticle}
\biboptions{round, numbers}
\usepackage[latin1]{inputenc}
%\usepackage[T1]{fontenc}
%\usepackage{textcomp}
\usepackage{graphicx}
%\usepackage{color}
%\usepackage{setspace}
\usepackage{url}
\usepackage[english]{babel}
\usepackage{todonotes}

\begin{document}

\begin{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   TITLE   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{[TENTATIVE] Can I navigate this web? Controlling URL accesses in the enterprise by means of categorical classifiers}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   AUTHORS   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author{P. de las Cuevas, A.M. Mora, J.J. Merelo}
\ead{\{paloma, amorag, jmerelo\}@geneura.ugr.es}
\address{Departamento de Arquitectura y Tecnología de Computadores.\\ ETSIIT - CITIC. University of Granada, Spain}
%\author{A. M. Mora}
%\ead{amorag@geneura.ugr.es}
%\address{Departamento de Arquitectura y Tecnología de Computadores. Escuela Técnica Superior de Ingenierías Informática y de Telecomunicación. CITIC. University of Granada, Spain}

%\maketitle

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   ABSTRACT   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{abstract} 

\end{abstract}

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   KEYWORDS   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{keyword}
Black List \sep White Lists \sep Data Mining \sep Corporate Security Policies \sep URL request\sep Machine Learning \sep Classification.
\end{keyword}

\end{frontmatter}


%-------------------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   INTRODUCTION   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------------------------------------------------------------------------------

\section{Introduction}
\label{sec:intro}

The concept of Security inside an Enterprise can be addressed from the point of view of the Internet connections that are daily being made. The employees who make these might have working purposes or not. The Enterprise, which is aware of this situation, wants to reduce the risks of security attacks introduced by some non trustworthy websites. Then, on a second level, but still important, companies want their employees to not to have their productivity decreased.

Above all the security tools that enterprises normally use, in this paper we focus in those named as Blacklists and Whitelists. Their use is widely extended, as they are easy to maintain, and each one has its advantages and disadvantages. The use of both highly increases the security in a company.
Indeed it is true that both Blacklists and Whitelists are easy to update or to maintain, because each day, new bad sites are reported. But at the same time, new sites (dangerous or not) are created. Netcraft reports from November shows that there are about 950 million active websites.

% Estadísticas de -> \cite{netcraft:site}

With this scenario, companies need to be able to update their Blacklists and Whitelists not only by what is reported by security servers but also by learning from the connections that the employees made in the past and were known as dangerous. This way, anomalous situations can be detected and also classified as candidates for the Blacklist or the Whitelist.

This work shows that this can be achieved by using categorical classifiers.

\begin{table*}[htpb]
\centering
 \caption{\label{featuretype} Extracted features from each entry of the Log and its dependance or independance on the user behaviour.}
{\scriptsize
\begin{tabular}{|l|l|l|}
\hline
\textbf{Feature name} & \textbf{Feature type} & \textbf{Relationship with user behaviour}\\ 
\hline
\texttt{http\_reply\_code} & Categorical & Independent \\ 
\texttt{http\_method} & Categorical & Independent \\ 
\texttt{duration\_milliseconds} & Numeric & Independent \\
\texttt{content\_type\_MCT} & Categorical & Independent \\ 
\texttt{content\_type} & Categorical & Independent \\ 
\texttt{server\_or\_cache\_address} & Categorical & Independent \\
\texttt{time} & Date & Dependent \\ 
\texttt{squid\_hierarchy} & Categorical & Independent \\ 
\texttt{bytes} & Numeric & Independent \\  
\texttt{URL\_length} & Numeric & Dependent \\  
\texttt{letters\_in\_URL} & Numeric & Dependent \\  
\texttt{digits\_in\_URL} & Numeric & Dependent \\  
\texttt{nonalphanumeric\_chars\_in\_URL} & Numeric & Dependent \\  
\texttt{url\_is\_IP} & Boolean & Dependent \\  
\texttt{url\_has\_subdomains} & Boolean & Dependent \\  
\texttt{num\_subdomains} & Numeric & Dependent \\  
\texttt{subdomain5} & Categorical & Dependent \\  
\texttt{subdomain4} & Categorical & Dependent \\  
\texttt{subdomain3} & Categorical & Dependent \\  
\texttt{subdomain2} & Categorical & Dependent \\  
\texttt{subdomain1} & Categorical & Dependent \\  
\texttt{url\_core} & Categorical & Dependent \\  
\texttt{url\_TLD} & Categorical & Dependent \\  
\texttt{url\_has\_path} & Boolean & Dependent \\  
\texttt{folder1} & Categorical & Dependent \\  
\texttt{folder2} & Categorical & Dependent \\  
\texttt{path\_has\_parameters} & Boolean & Dependent \\  
\texttt{num\_parameters} & Numeric & Dependent \\  
\texttt{url\_has\_file\_extension} & Boolean & Dependent \\  
\texttt{filename\_length} & Numeric & Dependent \\  
\texttt{letters\_in\_filename} & Numeric & Dependent \\  
\texttt{digits\_in\_filename} & Numeric & Dependent \\  
\texttt{other\_char\_in\_filename} & Numeric & Dependent \\  
\texttt{file\_extension} & Categorical & Dependent \\  
\texttt{url\_protocol} & Categorical & Dependent \\ 
\texttt{client\_address} & Categorical & Dependent \\ 
\texttt{label} & Categorical & Independent \\
\hline
\end{tabular}
}
\end{table*}



%----------------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%   BACKGROUND AND RELATED WORK %%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------------------------------------------

\section{Background and related work}
\label{sec:background_sota}

%*** Esta sección presentará conceptos de seguridad en la empresa, así como conceptos de machine learning y sus aplicaciones dentro de la seguridad corporativa, en concreto en aproximaciones similares a esta
%Creo que no tiene que ver y es repetir lo mismo all over again

*** Hay que diferenciar este trabajo de los existentes y destacar su avance en el estado del arte

%Network and internet security in enterprises
%URL classification

As in this work we are dedicating an important part to URL, its different parts and the way they influence in the classification process, this section is devoted to review some works related with the study of URLs. In particular, we found interesting those works that try to identify malicious sites (like the ones that want to perform a pishing attack). It is also interesting if they study the URL lexical features, like the one performed during this Master Thesis, and because we consider this kind of study better than to download and proccess the page (the thing that in fact is trying to be avoided). 

Hence, Kan and Thi \cite{Kan_URL05} focus their work in lexical features in order to classify as dangerous, URLs that were not previously in Blacklists servers. They gather features like the URI components, length, ortographic data, or segments by entropy reduction. Their results are close to 95\% of accuracy.

On the other hand, this work not only focuses in lexical features of the requested URL, but also in other data that appears in the log files. And not exactly log data but Zhang et al. \cite{Zhang_cantina07}, with CANTINA, detect pishing URLs by studying lexical features, content related features, and a WHOIS query (obtaining the date when the domain were registered, which if it is too new, it can be less trustful). They also obtain a 95\% of accuracy.

The most important work we have found related to this were of J. Ma et al \cite{Ma_Url11}, whose aim is to detect malicious URLs, mainly related with pishing attacks throug e-mailing, but without processing the content or other private data of the user. They extract information from the lexical features (62\% of the total of the gathered features), and also from the host that has the URL. It is important to point out that they perform the study over 100 days, and that they work with a quantity of almost 2 million of features. In addition, they implement an online classifier (instead of a batch one), and obtain a 99\% of accuracy. 

%Crime data mining and forensics in enterprise (?)

On the one hand, DM helped to develop new solutions to computer forensics \cite{DeVel2001}, being the researchers able to extract information from large files with events gathered from infected computers. Another important advance took place after the 9/11 events, when \textit{clustering techniques} and \textit{social network analysis} started to be performed in order to detect pontential crime networks \cite{Hsinchun2003}.
On the other hand, and more focused on the user side like our approach, there exist some user-centric solutions to problems like user authentication in a personal device, who Greenstadt and Beal \cite{cognitive_security_08} proposed to address using collected user biometrics along with machine learning techniques.

%feature extraction

%---------------------------------------------------------------------
%\subsection{Corporate Security}
%\label{subsec:corporatesecurity}

%---------------------------------------------------------------------
%\subsection{Machine Learning}
%\label{subsec:dm+ml}



%-------------------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  PROBLEM DEFINITION  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------------------------------------------------------------------------------

\section{Problem definition}
\label{sec:problem_data}

*** Definir el problema a resolver y describir los datos que se van a manejar en el mismo.

%----------------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   METODOLOGY  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------------------------------------------

\section{Metodology}
\label{sec:metodology}

*** Describir la metodología a seguir para la creación de los juegos de datos:
- preprocesado
- etiquetado para componer datos a clasificar
- técnicas de balanceo

*** Describir los 3 grandes bloques y justificarlos:
- Datos iniciales
- Características extraídas
- Sesiones

%---------------------------------------------------------------------
\subsection{Initial Data}
\label{subsec:initial_data}

*** Describir los primeros datos y procesamientos (eliminar duplicados, agrupar redundantes, etc)


%---------------------------------------------------------------------
\subsection{Extracting Features}
\label{subsec:extracting_features}

*** Describir y justificar las características extraídas de los datos iniciales.

%---------------------------------------------------------------------
\subsection{Grouping in Sessions}
\label{subsec:sessions}

*** Describir y justificar el proceso de agrupamiento en sesiones



%----------------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%%   EXPERIMENTS AND RESULTS  %%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------------------------------------------

\section{Experiments and Results}
\label{sec:experiments}

*** Describir los experimentos realizados, en cada bloque.
*** Analizar los resultados obtenidos en cada bloque

%---------------------------------------------------------------------
\subsection{Initial Data Results}
\label{subsec:initial_data_results}

*** Experimentos y resultados sobre el conjunto original y los conjuntos 'refinados' (TLD, sin duplicados, etc)


%---------------------------------------------------------------------
\subsection{Extracted Features Results}
\label{subsec:extracted_features_results}

*** Experimentos y resultados sobre el conjunto con las nuevas características


%---------------------------------------------------------------------
\subsection{Sessions Results}
\label{subsec:sessions_results}

*** Experimentos y resultados sobre el conjunto agrupando por sesiones



%----------------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   DISCUSSION  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------------------------------------------

\section{Discussion}
\label{sec:discussion}

*** Comentar los resultados de cada método y analizar las ventajas e inconvenientes de cada uno, así como las mejoras que se hayan conseguido con la extracción de características y el agrupamiento por sesiones


%----------------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   CONCLUSIONS  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------------------------------------------

\section{Conclusions and Future Work}
\label{sec:conclusions}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  ACKNOWLEDGEMENTS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Acknowledgements}
This work has been supported by the European project MUSES (FP7-318508).

\bibliographystyle{elsarticle-num}
\bibliography{review_muses,data_mining_urls,ci_security_rules}

\end{document}
